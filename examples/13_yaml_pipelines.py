#!/usr/bin/env python3
"""
ğŸ¢ Example 13: YAML Pipeline Definitions.

This example teaches:
- YAML-based pipeline definitions
- Pipeline compilation
- Enterprise pipeline features
- Pipeline catalog management

Run: python examples/13_yaml_pipelines.py
"""

import asyncio

from hexai.core.application.orchestrator import Orchestrator
from hexai.core.domain.dag import DirectedGraph, NodeSpec


async def data_loader(input_data: str) -> dict:
    """Load and parse input data."""
    return {"raw_input": input_data, "processed": True, "timestamp": "2024-01-01T10:00:00Z"}


async def text_processor(input_data: dict) -> dict:
    """Process text data."""
    text = input_data.get("raw_input", "")
    words = text.split()

    return {
        "word_count": len(words),
        "char_count": len(text),
        "processed_text": text.upper(),
        "original": input_data,
    }


async def sentiment_analyzer(input_data: dict) -> dict:
    """Analyze sentiment of text."""
    text = input_data.get("processed_text", "")

    # Simple sentiment analysis
    positive_words = ["good", "great", "excellent", "happy", "love"]
    negative_words = ["bad", "terrible", "awful", "hate", "sad"]

    text_lower = text.lower()
    positive_score = sum(1 for word in positive_words if word in text_lower)
    negative_score = sum(1 for word in negative_words if word in text_lower)

    if positive_score > negative_score:
        sentiment = "positive"
        confidence = min(0.9, (positive_score - negative_score) / 5)
    elif negative_score > positive_score:
        sentiment = "negative"
        confidence = min(0.9, (negative_score - positive_score) / 5)
    else:
        sentiment = "neutral"
        confidence = 0.5

    return {
        "sentiment": sentiment,
        "confidence": confidence,
        "positive_score": positive_score,
        "negative_score": negative_score,
        "analysis_data": input_data,
    }


async def report_generator(text_data: dict, sentiment_data: dict) -> dict:
    """Generate comprehensive report."""
    return {
        "report": {
            "text_summary": {
                "word_count": text_data.get("word_count", 0),
                "char_count": text_data.get("char_count", 0),
                "processed_text": text_data.get("processed_text", ""),
            },
            "sentiment_analysis": {
                "sentiment": sentiment_data.get("sentiment"),
                "confidence": sentiment_data.get("confidence"),
                "positive_score": sentiment_data.get("positive_score"),
                "negative_score": sentiment_data.get("negative_score"),
            },
            "timestamp": text_data.get("original", {}).get("timestamp"),
        },
        "analysis_complete": True,
    }


def create_yaml_pipeline_definition() -> str:
    """Create a YAML pipeline definition."""

    yaml_content = """
name: text_analysis_pipeline
version: "1.0.0"
description: "Analyze text sentiment and generate reports"

input_schema:
  type: string
  description: "Text to analyze"

output_schema:
  type: object
  properties:
    report:
      type: object
      properties:
        text_summary:
          type: object
        sentiment_analysis:
          type: object
    analysis_complete:
      type: boolean

nodes:
  data_loader:
    type: function
    function: data_loader
    description: "Load and parse input data"

  text_processor:
    type: function
    function: text_processor
    depends_on: ["data_loader"]
    description: "Process and analyze text content"

  sentiment_analyzer:
    type: function
    function: sentiment_analyzer
    depends_on: ["text_processor"]
    description: "Analyze sentiment of processed text"

  report_generator:
    type: function
    function: report_generator
    depends_on: ["text_processor", "sentiment_analyzer"]
    description: "Generate comprehensive analysis report"

config:
  validation_strategy: "coerce"
  max_concurrent_nodes: 4
  timeout_seconds: 300
"""

    return yaml_content


def create_simple_yaml_pipeline() -> str:
    """Create a simpler YAML pipeline for demonstration."""

    yaml_content = """
name: simple_text_pipeline
version: "1.0.0"
description: "Simple text processing pipeline"

nodes:
  process:
    type: function
    function: text_processor
    description: "Process input text"

  analyze:
    type: function
    function: sentiment_analyzer
    depends_on: ["process"]
    description: "Analyze sentiment"

config:
  validation_strategy: "coerce"
"""

    return yaml_content


async def demonstrate_yaml_parsing():
    """Demonstrate parsing YAML pipeline definitions."""

    print("\nğŸ“„ YAML Pipeline Definition Demo")
    print("=" * 40)

    # Create YAML content
    yaml_content = create_yaml_pipeline_definition()

    print("\nğŸ“‹ YAML Pipeline Definition:")
    print("   (Showing key parts of the YAML)")
    print("   â€¢ Pipeline name: text_analysis_pipeline")
    print("   â€¢ Version: 1.0.0")
    print("   â€¢ Nodes: 4 (data_loader, text_processor, sentiment_analyzer, report_generator)")
    print("   â€¢ Dependencies: Complex multi-level dependencies")
    print("   â€¢ Config: coerce validation, 4 concurrent nodes")

    # Show the structure
    print("\nğŸ—ï¸  Pipeline Structure:")
    print("   data_loader")
    print("   â””â”€â”€ text_processor")
    print("       â”œâ”€â”€ sentiment_analyzer")
    print("       â””â”€â”€ report_generator")
    print("           â””â”€â”€ (depends on both text_processor and sentiment_analyzer)")

    return yaml_content


async def demonstrate_pipeline_execution():
    """Demonstrate executing a pipeline from YAML."""

    print("\nğŸš€ Pipeline Execution Demo")
    print("=" * 40)

    # Create the DAG manually (simulating YAML parsing)
    graph = DirectedGraph()

    # Add nodes
    graph.add(NodeSpec("data_loader", data_loader))
    graph.add(NodeSpec("text_processor", text_processor).after("data_loader"))
    graph.add(NodeSpec("sentiment_analyzer", sentiment_analyzer).after("text_processor"))
    graph.add(
        NodeSpec("report_generator", report_generator).after("text_processor", "sentiment_analyzer")
    )

    # Validate
    graph.validate()

    print("\nğŸ“Š Pipeline Analysis:")
    waves = graph.waves()
    print(f"   â€¢ Total waves: {len(waves)}")
    for i, wave in enumerate(waves, 1):
        print(f"   â€¢ Wave {i}: {wave}")

    # Execute
    orchestrator = Orchestrator()

    test_inputs = [
        "I love this product! It's amazing and wonderful.",
        "This is terrible. I hate it so much.",
        "The product is okay. Not great, not bad.",
    ]

    for i, test_input in enumerate(test_inputs, 1):
        print(f"\nğŸ§ª Test {i}: '{test_input[:30]}...'")

        try:
            results = await orchestrator.run(graph, test_input)

            report = results.get("report_generator", {}).get("report", {})
            sentiment = report.get("sentiment_analysis", {})

            confidence = sentiment.get("confidence", 0)
            print(f"   ğŸ“ˆ Sentiment: {sentiment.get('sentiment')} (confidence: {confidence:.2f})")
            print(f"   ğŸ“Š Word count: {report.get('text_summary', {}).get('word_count', 0)}")
            analysis_complete = results.get("report_generator", {}).get("analysis_complete", False)
            print(f"   âœ… Analysis complete: {analysis_complete}")

        except Exception as e:
            print(f"   âŒ Execution failed: {e}")

    return graph


async def demonstrate_pipeline_compilation():
    """Demonstrate pipeline compilation concepts."""

    print("\nâš™ï¸ Pipeline Compilation Demo")
    print("=" * 40)

    # Simulate compilation steps
    print("\nğŸ”§ Compilation Steps:")
    print("   1. Parse YAML definition")
    print("   2. Validate node dependencies")
    print("   3. Generate execution plan")
    print("   4. Optimize for performance")
    print("   5. Generate type stubs")
    print("   6. Create compiled pipeline")

    # Show compilation benefits
    print("\nğŸ’¡ Compilation Benefits:")
    print("   â€¢ Type safety validation")
    print("   â€¢ Performance optimization")
    print("   â€¢ Early error detection")
    print("   â€¢ Code generation")
    print("   â€¢ Schema validation")

    # Simulate compiled output
    print("\nğŸ“¦ Compiled Pipeline Features:")
    print("   â€¢ Optimized execution order")
    print("   â€¢ Type-validated inputs/outputs")
    print("   â€¢ Error handling built-in")
    print("   â€¢ Performance monitoring hooks")
    print("   â€¢ Schema compatibility checks")


async def demonstrate_pipeline_catalog():
    """Demonstrate pipeline catalog management."""

    print("\nğŸ“š Pipeline Catalog Demo")
    print("=" * 40)

    # Simulate catalog operations
    pipelines = {
        "text_analysis": {
            "version": "1.0.0",
            "description": "Analyze text sentiment",
            "nodes": 4,
            "status": "active",
        },
        "simple_text": {
            "version": "1.0.0",
            "description": "Simple text processing",
            "nodes": 2,
            "status": "active",
        },
        "data_processing": {
            "version": "0.9.0",
            "description": "Data processing pipeline",
            "nodes": 6,
            "status": "beta",
        },
    }

    print("\nğŸ“‹ Available Pipelines:")
    for name, info in pipelines.items():
        status_icon = "âœ…" if info["status"] == "active" else "ğŸŸ¡"
        print(f"   {status_icon} {name} v{info['version']} ({info['nodes']} nodes)")
        print(f"      {info['description']}")

    print("\nğŸ” Catalog Operations:")
    print("   â€¢ List available pipelines")
    print("   â€¢ Get pipeline metadata")
    print("   â€¢ Version management")
    print("   â€¢ Dependency tracking")
    print("   â€¢ Usage statistics")


async def main():
    """Demonstrate YAML pipeline features."""

    print("ğŸ¢ Example 13: YAML Pipeline Definitions")
    print("=" * 50)

    print("\nğŸ¯ This example demonstrates:")
    print("   â€¢ YAML-based pipeline definitions")
    print("   â€¢ Pipeline compilation concepts")
    print("   â€¢ Enterprise pipeline features")
    print("   â€¢ Pipeline catalog management")
    print("   â€¢ Complex dependency handling")

    await demonstrate_yaml_parsing()
    await demonstrate_pipeline_execution()
    await demonstrate_pipeline_compilation()
    await demonstrate_pipeline_catalog()

    print("\nğŸ¯ Key Concepts Learned:")
    print("   âœ… YAML Definitions - Declarative pipeline specification")
    print("   âœ… Pipeline Compilation - Type safety and optimization")
    print("   âœ… Enterprise Features - Catalog management and versioning")
    print("   âœ… Complex Dependencies - Multi-level node relationships")
    print("   âœ… Validation Strategies - Configurable validation behavior")

    print("\nğŸ’¡ Enterprise Benefits:")
    print("   â€¢ Declarative pipeline definitions")
    print("   â€¢ Version control and management")
    print("   â€¢ Type safety and validation")
    print("   â€¢ Performance optimization")
    print("   â€¢ Team collaboration")

    print("\nğŸ”— Next: Run example 14 to learn about pipeline compilation!")


if __name__ == "__main__":
    asyncio.run(main())
