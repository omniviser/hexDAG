{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Review & Security Audit System\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demonstrates an enterprise-grade automated code review system that:\n",
    "- **Analyzes code** for bugs, vulnerabilities, and best practices\n",
    "- **Maintains review dialogue** with developers through conversation agents\n",
    "- **Enforces security policies** with automated blocking of vulnerable code\n",
    "- **Ensures compliance** with license and regulatory requirements\n",
    "\n",
    "## Business Value\n",
    "\n",
    "- üõ°Ô∏è **90% reduction** in security vulnerabilities reaching production\n",
    "- ‚ö° **75% faster** code reviews with AI assistance\n",
    "- üìä **100% coverage** of security and compliance checks\n",
    "- üîÑ **Continuous learning** from review history\n",
    "\n",
    "## Architecture\n",
    "\n",
    "The system uses:\n",
    "- **conversation macro**: Interactive review discussions with context\n",
    "- **reasoning_agent macro**: Deep code analysis with security tools\n",
    "- **Policies**: Security, performance, license, and code quality enforcement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import hashlib\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "from typing import Any\n",
    "\n",
    "# Set environment\n",
    "os.environ[\"HEXDAG_ENV\"] = \"dev\"  # Switch to \"prod\" for production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define Security and Compliance Policies\n",
    "\n",
    "These policies automatically detect and prevent common security issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "\n",
    "# Policy support is planned - these are stub classes for the demo\n",
    "class PolicySignal(Enum):\n",
    "    \"\"\"Signal returned by a policy evaluation.\"\"\"\n",
    "\n",
    "    PROCEED = \"proceed\"  # Allow the operation\n",
    "    FAIL = \"fail\"  # Block the operation\n",
    "    SKIP = \"skip\"  # Skip but don't fail\n",
    "\n",
    "\n",
    "class PolicyResponse:\n",
    "    \"\"\"Response from a policy evaluation.\"\"\"\n",
    "\n",
    "    def __init__(self, signal: PolicySignal, metadata: dict[str, Any] | None = None):\n",
    "        self.signal = signal\n",
    "        self.metadata = metadata or {}\n",
    "\n",
    "\n",
    "# Policies are plain Python classes\n",
    "# Reference in YAML pipelines by full module path\n",
    "\n",
    "\n",
    "class SecurityVulnerabilityPolicy:\n",
    "    \"\"\"Detects common security vulnerabilities in code.\"\"\"\n",
    "\n",
    "    def __init__(self, block_critical: bool = True, scan_depth: str = \"deep\"):\n",
    "        self.block_critical = block_critical\n",
    "        self.scan_depth = scan_depth\n",
    "\n",
    "        # Common vulnerability patterns\n",
    "        self.vulnerability_patterns = {\n",
    "            \"sql_injection\": r\"(SELECT|INSERT|UPDATE|DELETE).*\\+.*(?:request|input|param)\",\n",
    "            \"command_injection\": r\"(exec|system|eval|subprocess)\\s*\\(.*(?:request|input|user)\",\n",
    "            \"xss\": r\"innerHTML\\s*=.*(?:request|input|param)\",\n",
    "            \"path_traversal\": r\"\\.\\.[\\\\\\/]\",\n",
    "            \"hardcoded_secrets\": r\"(api_key|password|secret|token)\\s*=\\s*['\\\"][^'\\\"]+['\\\"]\",\n",
    "            \"weak_crypto\": r\"(md5|sha1)\\s*\\(\",\n",
    "        }\n",
    "\n",
    "    async def evaluate(self, context: dict[str, Any]) -> PolicyResponse:\n",
    "        metadata = context.get(\"metadata\", {})\n",
    "        code = metadata.get(\"code\", \"\")\n",
    "        file_path = metadata.get(\"file_path\", \"unknown\")\n",
    "\n",
    "        vulnerabilities = []\n",
    "        severity_score = 0\n",
    "\n",
    "        # Scan for vulnerabilities\n",
    "        for vuln_type, pattern in self.vulnerability_patterns.items():\n",
    "            if re.search(pattern, code, re.IGNORECASE):\n",
    "                vulnerabilities.append(vuln_type)\n",
    "\n",
    "                # Assign severity scores\n",
    "                if vuln_type in [\"sql_injection\", \"command_injection\", \"hardcoded_secrets\"]:\n",
    "                    severity_score += 10  # Critical\n",
    "                elif vuln_type in [\"xss\", \"path_traversal\"]:\n",
    "                    severity_score += 7  # High\n",
    "                else:\n",
    "                    severity_score += 3  # Medium\n",
    "\n",
    "        if vulnerabilities:\n",
    "            if severity_score >= 10 and self.block_critical:\n",
    "                return PolicyResponse(\n",
    "                    signal=PolicySignal.FAIL,\n",
    "                    metadata={\n",
    "                        \"message\": f\"CRITICAL: Found {len(vulnerabilities)} vulnerabilities: {', '.join(vulnerabilities)}\",\n",
    "                        \"vulnerabilities\": vulnerabilities,\n",
    "                        \"severity_score\": severity_score,\n",
    "                        \"file\": file_path,\n",
    "                    },\n",
    "                )\n",
    "            return PolicyResponse(\n",
    "                signal=PolicySignal.PROCEED,\n",
    "                metadata={\n",
    "                    \"message\": f\"Found {len(vulnerabilities)} potential vulnerabilities\",\n",
    "                    \"vulnerabilities\": vulnerabilities,\n",
    "                    \"warning\": True,\n",
    "                },\n",
    "            )\n",
    "\n",
    "        return PolicyResponse(\n",
    "            signal=PolicySignal.PROCEED,\n",
    "            metadata={\"message\": \"No security vulnerabilities detected\"},\n",
    "        )\n",
    "\n",
    "\n",
    "class CodeQualityPolicy:\n",
    "    \"\"\"Enforces code quality and best practices.\"\"\"\n",
    "\n",
    "    def __init__(self, max_complexity: int = 10, max_line_length: int = 120):\n",
    "        self.max_complexity = max_complexity\n",
    "        self.max_line_length = max_line_length\n",
    "\n",
    "    async def evaluate(self, context: dict[str, Any]) -> PolicyResponse:\n",
    "        metadata = context.get(\"metadata\", {})\n",
    "        code = metadata.get(\"code\", \"\")\n",
    "        metrics = metadata.get(\"metrics\", {})\n",
    "\n",
    "        issues = []\n",
    "\n",
    "        # Check cyclomatic complexity\n",
    "        complexity = metrics.get(\"cyclomatic_complexity\", 0)\n",
    "        if complexity > self.max_complexity:\n",
    "            issues.append(f\"High complexity: {complexity} (max: {self.max_complexity})\")\n",
    "\n",
    "        # Check line length\n",
    "        lines = code.split(\"\\n\")\n",
    "        long_lines = [i + 1 for i, line in enumerate(lines) if len(line) > self.max_line_length]\n",
    "        if long_lines:\n",
    "            issues.append(f\"Long lines at: {long_lines[:5]}{'...' if len(long_lines) > 5 else ''}\")\n",
    "\n",
    "        # Check for code smells\n",
    "        if \"TODO\" in code or \"FIXME\" in code or \"HACK\" in code:\n",
    "            issues.append(\"Unresolved TODOs/FIXMEs found\")\n",
    "\n",
    "        if re.search(r\"except\\s*:\", code):\n",
    "            issues.append(\"Bare except clause found\")\n",
    "\n",
    "        if issues:\n",
    "            return PolicyResponse(\n",
    "                signal=PolicySignal.PROCEED,\n",
    "                metadata={\n",
    "                    \"message\": f\"Code quality issues: {'; '.join(issues)}\",\n",
    "                    \"issues\": issues,\n",
    "                    \"warning\": True,\n",
    "                },\n",
    "            )\n",
    "\n",
    "        return PolicyResponse(\n",
    "            signal=PolicySignal.PROCEED, metadata={\"message\": \"Code quality standards met\"}\n",
    "        )\n",
    "\n",
    "\n",
    "class LicenseCompliancePolicy:\n",
    "    \"\"\"Ensures all dependencies have compatible licenses.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, allowed_licenses: list[str] | None = None, blocked_licenses: list[str] | None = None\n",
    "    ):\n",
    "        self.allowed_licenses = allowed_licenses or [\"MIT\", \"Apache-2.0\", \"BSD-3-Clause\", \"ISC\"]\n",
    "        self.blocked_licenses = blocked_licenses or [\"GPL-3.0\", \"AGPL-3.0\", \"Proprietary\"]\n",
    "\n",
    "    async def evaluate(self, context: dict[str, Any]) -> PolicyResponse:\n",
    "        metadata = context.get(\"metadata\", {})\n",
    "        dependencies = metadata.get(\"dependencies\", [])\n",
    "\n",
    "        blocked_deps = []\n",
    "        unknown_deps = []\n",
    "\n",
    "        for dep in dependencies:\n",
    "            license_type = dep.get(\"license\", \"Unknown\")\n",
    "\n",
    "            if license_type in self.blocked_licenses:\n",
    "                blocked_deps.append(f\"{dep['name']} ({license_type})\")\n",
    "            elif license_type not in self.allowed_licenses and license_type != \"Unknown\":\n",
    "                unknown_deps.append(f\"{dep['name']} ({license_type})\")\n",
    "\n",
    "        if blocked_deps:\n",
    "            return PolicyResponse(\n",
    "                signal=PolicySignal.FAIL,\n",
    "                metadata={\n",
    "                    \"message\": f\"Incompatible licenses found: {', '.join(blocked_deps)}\",\n",
    "                    \"blocked_dependencies\": blocked_deps,\n",
    "                },\n",
    "            )\n",
    "\n",
    "        if unknown_deps:\n",
    "            return PolicyResponse(\n",
    "                signal=PolicySignal.PROCEED,\n",
    "                metadata={\n",
    "                    \"message\": f\"Unknown licenses require review: {', '.join(unknown_deps)}\",\n",
    "                    \"unknown_dependencies\": unknown_deps,\n",
    "                    \"warning\": True,\n",
    "                },\n",
    "            )\n",
    "\n",
    "        return PolicyResponse(\n",
    "            signal=PolicySignal.PROCEED, metadata={\"message\": \"All licenses are compliant\"}\n",
    "        )\n",
    "\n",
    "\n",
    "class PerformancePolicy:\n",
    "    \"\"\"Detects potential performance bottlenecks.\"\"\"\n",
    "\n",
    "    def __init__(self, warn_on_n_plus_one: bool = True, max_db_queries: int = 10):\n",
    "        self.warn_on_n_plus_one = warn_on_n_plus_one\n",
    "        self.max_db_queries = max_db_queries\n",
    "\n",
    "    async def evaluate(self, context: dict[str, Any]) -> PolicyResponse:\n",
    "        metadata = context.get(\"metadata\", {})\n",
    "        code = metadata.get(\"code\", \"\")\n",
    "        performance_issues = []\n",
    "\n",
    "        # Check for N+1 query patterns\n",
    "        if self.warn_on_n_plus_one and re.search(r\"for.*in.*:\\s*\\n.*\\.objects\\.\", code):\n",
    "            performance_issues.append(\"Potential N+1 query detected\")\n",
    "\n",
    "        # Check for inefficient operations\n",
    "        if \"sleep(\" in code or \"time.sleep(\" in code:\n",
    "            performance_issues.append(\"Synchronous sleep detected\")\n",
    "\n",
    "        if re.search(r\"\\*\\s*from\\s+\", code):\n",
    "            performance_issues.append(\"SELECT * query detected\")\n",
    "\n",
    "        # Check for missing indexes\n",
    "        if \"filter(\" in code and \"db_index=True\" not in code:\n",
    "            performance_issues.append(\"Potential missing database index\")\n",
    "\n",
    "        if performance_issues:\n",
    "            return PolicyResponse(\n",
    "                signal=PolicySignal.PROCEED,\n",
    "                metadata={\n",
    "                    \"message\": f\"Performance concerns: {'; '.join(performance_issues)}\",\n",
    "                    \"issues\": performance_issues,\n",
    "                    \"warning\": True,\n",
    "                },\n",
    "            )\n",
    "\n",
    "        return PolicyResponse(\n",
    "            signal=PolicySignal.PROCEED, metadata={\"message\": \"No performance issues detected\"}\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Policy Summary\n",
    "\n",
    "The policies defined above will enforce security, quality, and compliance standards in our code review pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"‚úÖ Custom security and compliance policies defined\")\n",
    "print(\"\\nPolicies available:\")\n",
    "print(\"‚Ä¢ SecurityVulnerabilityPolicy - Detects SQL injection, XSS, secrets, etc.\")\n",
    "print(\"‚Ä¢ CodeQualityPolicy - Enforces complexity, line length, code smell checks\")\n",
    "print(\"‚Ä¢ LicenseCompliancePolicy - Validates dependency licenses\")\n",
    "print(\"‚Ä¢ PerformancePolicy - Flags N+1 queries, blocking I/O, inefficiencies\")\n",
    "print(\"\\nThese policies will be used by the pipeline to enforce code standards.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Supporting Functions and Security Tools\n",
    "\n",
    "These functions and tools will be used by the code review pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "# Tools are plain functions with type hints and docstrings\n",
    "# Reference in YAML as: tools: [mymodule.scan_dependencies]\n",
    "\n",
    "\n",
    "# Code loading and analysis functions\n",
    "async def load_code_for_review(\n",
    "    file_path: str = \"example.py\", pr_number: str = \"123\"\n",
    ") -> dict[str, Any]:\n",
    "    \"\"\"Load code for review from file or PR.\"\"\"\n",
    "\n",
    "    # Example code with intentional issues for demonstration\n",
    "    example_code = '''\n",
    "import os\n",
    "import subprocess\n",
    "from database import db\n",
    "\n",
    "API_KEY = \"sk-1234567890abcdef\"  # TODO: Move to env\n",
    "\n",
    "def process_user_input(user_input, user_id):\n",
    "    \"\"\"Process user input and execute query.\"\"\"\n",
    "    # Potential SQL injection\n",
    "    query = f\"SELECT * FROM users WHERE id = {user_id} AND name = '{user_input}'\"\n",
    "    results = db.execute(query)\n",
    "    \n",
    "    # Potential command injection\n",
    "    if user_input.startswith(\"exec:\"):\n",
    "        cmd = user_input[5:]\n",
    "        output = subprocess.check_output(cmd, shell=True)\n",
    "        return output\n",
    "    \n",
    "    # N+1 query problem\n",
    "    for result in results:\n",
    "        profile = db.execute(f\"SELECT * FROM profiles WHERE user_id = {result['id']}\")\n",
    "        result['profile'] = profile\n",
    "    \n",
    "    return results\n",
    "\n",
    "def weak_hash_password(password):\n",
    "    \"\"\"Hash password using weak algorithm.\"\"\"\n",
    "    import hashlib\n",
    "    return hashlib.md5(password.encode()).hexdigest()  # Weak crypto\n",
    "'''\n",
    "\n",
    "    commit_hash = hashlib.md5(example_code.encode()).hexdigest()[:8]\n",
    "\n",
    "    return {\n",
    "        \"code\": example_code,\n",
    "        \"file_path\": file_path,\n",
    "        \"pr_number\": pr_number,\n",
    "        \"commit_hash\": commit_hash,\n",
    "        \"language\": \"python\",\n",
    "        \"lines_of_code\": len(example_code.split(\"\\n\")),\n",
    "    }\n",
    "\n",
    "\n",
    "async def run_static_analysis(code_loader: dict) -> dict[str, Any]:\n",
    "    \"\"\"Run static code analysis.\"\"\"\n",
    "    code = code_loader[\"code\"]\n",
    "\n",
    "    # Basic static analysis\n",
    "    results = {\"issues\": [], \"metrics\": {}, \"dependencies\": []}\n",
    "\n",
    "    # Parse AST for analysis\n",
    "    try:\n",
    "        tree = ast.parse(code)\n",
    "\n",
    "        # Count functions and classes\n",
    "        functions = [node for node in ast.walk(tree) if isinstance(node, ast.FunctionDef)]\n",
    "        classes = [node for node in ast.walk(tree) if isinstance(node, ast.ClassDef)]\n",
    "\n",
    "        results[\"metrics\"] = {\n",
    "            \"functions\": len(functions),\n",
    "            \"classes\": len(classes),\n",
    "            \"cyclomatic_complexity\": len(functions) * 3,  # Simplified\n",
    "            \"lines_of_code\": code_loader[\"lines_of_code\"],\n",
    "        }\n",
    "\n",
    "        # Check for common issues\n",
    "        if \"exec(\" in code or \"eval(\" in code:\n",
    "            results[\"issues\"].append(\"Use of eval/exec detected\")\n",
    "\n",
    "        if \"import *\" in code:\n",
    "            results[\"issues\"].append(\"Wildcard imports detected\")\n",
    "\n",
    "        # Extract imports as dependencies\n",
    "        for node in ast.walk(tree):\n",
    "            if isinstance(node, ast.Import):\n",
    "                for alias in node.names:\n",
    "                    results[\"dependencies\"].append({\n",
    "                        \"name\": alias.name,\n",
    "                        \"license\": \"MIT\",  # Simplified\n",
    "                    })\n",
    "\n",
    "    except SyntaxError as e:\n",
    "        results[\"issues\"].append(f\"Syntax error: {e}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# Security analysis tools\n",
    "def scan_dependencies(dependencies: list[dict]) -> dict[str, Any]:\n",
    "    \"\"\"Scan project dependencies for known vulnerabilities.\n",
    "\n",
    "    Args:\n",
    "        dependencies: List of dependency dictionaries with 'name' keys\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with vulnerability scan results\n",
    "    \"\"\"\n",
    "    vulnerabilities = []\n",
    "\n",
    "    # Simulated vulnerability database\n",
    "    vuln_db = {\n",
    "        \"requests<2.28.0\": \"CVE-2022-1234: SSRF vulnerability\",\n",
    "        \"django<3.2\": \"CVE-2021-5678: SQL injection\",\n",
    "        \"flask<2.0\": \"CVE-2020-9101: XSS vulnerability\",\n",
    "    }\n",
    "\n",
    "    for dep in dependencies:\n",
    "        for pattern, vuln in vuln_db.items():\n",
    "            if pattern.split(\"<\")[0] in dep.get(\"name\", \"\"):\n",
    "                vulnerabilities.append({\n",
    "                    \"dependency\": dep[\"name\"],\n",
    "                    \"vulnerability\": vuln,\n",
    "                    \"severity\": \"HIGH\",\n",
    "                })\n",
    "\n",
    "    return {\n",
    "        \"total_scanned\": len(dependencies),\n",
    "        \"vulnerabilities_found\": len(vulnerabilities),\n",
    "        \"details\": vulnerabilities,\n",
    "    }\n",
    "\n",
    "\n",
    "def check_cve_database(code_patterns: list[str]) -> list[dict]:\n",
    "    \"\"\"Check code patterns against CVE database.\n",
    "\n",
    "    Args:\n",
    "        code_patterns: List of code patterns to check\n",
    "\n",
    "    Returns:\n",
    "        List of matching CVE entries\n",
    "    \"\"\"\n",
    "    # Simulated CVE check\n",
    "    return [\n",
    "        {\n",
    "            \"cve_id\": \"CVE-2023-1234\",\n",
    "            \"description\": \"Potential SQL injection pattern detected\",\n",
    "            \"severity\": \"CRITICAL\",\n",
    "            \"remediation\": \"Use parameterized queries\",\n",
    "        }\n",
    "    ]\n",
    "\n",
    "\n",
    "def analyze_crypto(code: str) -> dict[str, Any]:\n",
    "    \"\"\"Analyze cryptographic implementations for weaknesses.\n",
    "\n",
    "    Args:\n",
    "        code: Source code to analyze\n",
    "\n",
    "    Returns:\n",
    "        Analysis results with findings\n",
    "    \"\"\"\n",
    "    weak_algorithms = [\"md5\", \"sha1\", \"des\", \"rc4\"]\n",
    "\n",
    "    findings = [\n",
    "        {\n",
    "            \"algorithm\": algo.upper(),\n",
    "            \"risk\": \"Weak cryptographic algorithm\",\n",
    "            \"recommendation\": f\"Replace {algo.upper()} with SHA-256 or stronger\",\n",
    "        }\n",
    "        for algo in weak_algorithms\n",
    "        if algo in code.lower()\n",
    "    ]\n",
    "\n",
    "    return {\"weak_crypto_found\": len(findings) > 0, \"findings\": findings}\n",
    "\n",
    "\n",
    "# Code quality tools\n",
    "def calculate_complexity(code: str) -> dict[str, int]:\n",
    "    \"\"\"Calculate cyclomatic complexity and other metrics.\n",
    "\n",
    "    Args:\n",
    "        code: Source code to analyze\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with complexity metrics\n",
    "    \"\"\"\n",
    "    # Simplified complexity calculation\n",
    "    complexity = 1\n",
    "    complexity += code.count(\"if \")\n",
    "    complexity += code.count(\"elif \")\n",
    "    complexity += code.count(\"for \")\n",
    "    complexity += code.count(\"while \")\n",
    "    complexity += code.count(\"except \")\n",
    "\n",
    "    return {\n",
    "        \"cyclomatic_complexity\": complexity,\n",
    "        \"cognitive_complexity\": complexity * 1.5,\n",
    "        \"maintainability_index\": max(0, 100 - complexity * 5),\n",
    "    }\n",
    "\n",
    "\n",
    "def suggest_fix(issue: str, code_context: str) -> str:\n",
    "    \"\"\"Suggest fixes for identified issues.\n",
    "\n",
    "    Args:\n",
    "        issue: Description of the issue\n",
    "        code_context: Code context around the issue\n",
    "\n",
    "    Returns:\n",
    "        Suggested fix as a string\n",
    "    \"\"\"\n",
    "    fixes = {\n",
    "        \"sql_injection\": \"Use parameterized queries: cursor.execute('SELECT * FROM users WHERE id = ?', (user_id,))\",\n",
    "        \"hardcoded_secrets\": \"Use environment variables: api_key = os.environ.get('API_KEY')\",\n",
    "        \"weak_crypto\": \"Use strong hashing: hashlib.pbkdf2_hmac('sha256', password.encode(), salt, 100000)\",\n",
    "    }\n",
    "\n",
    "    for pattern, fix in fixes.items():\n",
    "        if pattern in issue.lower():\n",
    "            return fix\n",
    "\n",
    "    return \"Please consult security best practices documentation\"\n",
    "\n",
    "\n",
    "# Report generation\n",
    "async def compile_review_report(\n",
    "    review_discussion: dict,\n",
    "    security_scanner: dict,\n",
    "    code_reviewer: dict,\n",
    "    static_analyzer: dict,\n",
    "    include_metrics: bool = True,\n",
    "    generate_badge: bool = True,\n",
    ") -> dict[str, Any]:\n",
    "    \"\"\"Compile comprehensive review report.\"\"\"\n",
    "\n",
    "    # Calculate overall score\n",
    "    security_score = 10  # Start with perfect score\n",
    "    quality_score = 10\n",
    "\n",
    "    # Deduct for issues\n",
    "    issues = static_analyzer.get(\"issues\", [])\n",
    "    security_score -= len(issues) * 0.5\n",
    "\n",
    "    metrics = static_analyzer.get(\"metrics\", {})\n",
    "    if metrics.get(\"cyclomatic_complexity\", 0) > 10:\n",
    "        quality_score -= 2\n",
    "\n",
    "    overall_score = (security_score + quality_score) / 2\n",
    "\n",
    "    report = {\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"summary\": {\n",
    "            \"overall_score\": overall_score,\n",
    "            \"security_score\": security_score,\n",
    "            \"quality_score\": quality_score,\n",
    "            \"status\": \"APPROVED\" if overall_score >= 7 else \"CHANGES_REQUESTED\",\n",
    "        },\n",
    "        \"security_findings\": security_scanner.get(\"output\", \"No security analysis available\"),\n",
    "        \"code_review\": code_reviewer.get(\"output\", \"No code review available\"),\n",
    "        \"conversation\": review_discussion.get(\"output\", \"No discussion available\"),\n",
    "    }\n",
    "\n",
    "    if include_metrics:\n",
    "        report[\"metrics\"] = metrics\n",
    "\n",
    "    if generate_badge:\n",
    "        badge_color = \"green\" if overall_score >= 8 else \"yellow\" if overall_score >= 6 else \"red\"\n",
    "        report[\"badge\"] = {\n",
    "            \"score\": f\"{overall_score:.1f}/10\",\n",
    "            \"color\": badge_color,\n",
    "            \"url\": f\"https://img.shields.io/badge/Code%20Review-{overall_score:.1f}%2F10-{badge_color}\",\n",
    "        }\n",
    "\n",
    "    return report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Execute Code Review Pipeline\n",
    "\n",
    "Let's run a working version of the code review pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified working pipeline that can execute\n",
    "from hexdag.compiler import YamlPipelineBuilder\n",
    "from hexdag.kernel.orchestration.orchestrator import Orchestrator\n",
    "from hexdag.stdlib.adapters.mock.mock_llm import MockLLM\n",
    "\n",
    "working_pipeline_yaml = \"\"\"\n",
    "apiVersion: hexdag/v1\n",
    "kind: Pipeline\n",
    "metadata:\n",
    "  name: code-review-demo\n",
    "  description: Simple code review pipeline\n",
    "\n",
    "spec:\n",
    "  nodes:\n",
    "    - kind: llm_node\n",
    "      metadata:\n",
    "        name: security_check\n",
    "        description: Check for security issues\n",
    "      spec:\n",
    "        template: |\n",
    "          Analyze this code for vulnerabilities:\n",
    "          ```python\n",
    "          API_KEY = \"sk-12345\"\n",
    "          query = f\"SELECT * FROM users WHERE id = {user_id}\"\n",
    "          subprocess.check_output(user_input, shell=True)\n",
    "          ```\n",
    "      depends_on: []\n",
    "\n",
    "    - kind: llm_node\n",
    "      metadata:\n",
    "        name: quality_check\n",
    "        description: Check code quality\n",
    "      spec:\n",
    "        template: |\n",
    "          Review code quality and suggest improvements.\n",
    "      depends_on: []\n",
    "\n",
    "    - kind: llm_node\n",
    "      metadata:\n",
    "        name: final_summary\n",
    "        description: Summarize findings\n",
    "      spec:\n",
    "        template: |\n",
    "          Provide a final review summary and recommendation.\n",
    "      depends_on: [security_check, quality_check]\n",
    "\"\"\"\n",
    "\n",
    "# Build the pipeline\n",
    "print(\"üîß Building code review pipeline...\")\n",
    "builder = YamlPipelineBuilder()\n",
    "graph, config = builder.build_from_yaml_string(working_pipeline_yaml)\n",
    "\n",
    "print(\"‚úÖ Pipeline built successfully!\")\n",
    "print(f\"   Nodes: {len(graph.nodes)} nodes\")\n",
    "\n",
    "# Create custom mock LLM with specific responses\n",
    "custom_llm = MockLLM(\n",
    "    responses=[\n",
    "        \"\"\"üö® Security Issues Found:\n",
    "- SQL Injection on line 10\n",
    "- Hardcoded API key on line 5\n",
    "- Command injection risk on line 17\n",
    "\n",
    "Severity: CRITICAL\"\"\",\n",
    "        \"\"\"üìù Code Quality Analysis:\n",
    "- High cyclomatic complexity (score: 15)\n",
    "- Missing documentation\n",
    "- No unit tests found\n",
    "\n",
    "Recommendation: Refactor and add tests\"\"\",\n",
    "        \"\"\"üìä Final Review Summary:\n",
    "\n",
    "Critical security issues require immediate attention.\n",
    "Code quality needs improvement before merge.\n",
    "\n",
    "Recommendation: REQUEST CHANGES\"\"\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create orchestrator with adapters from config\n",
    "print(\"\\nüöÄ Running code review...\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Create orchestrator with custom LLM\n",
    "orchestrator = Orchestrator(ports={\"llm\": custom_llm})\n",
    "\n",
    "\n",
    "# Run the pipeline - compatible with both interactive Jupyter and nbconvert\n",
    "async def run_review():\n",
    "    return await orchestrator.run(graph=graph, initial_input={})\n",
    "\n",
    "\n",
    "# Check if we're in a running event loop (interactive Jupyter)\n",
    "try:\n",
    "    loop = asyncio.get_running_loop()\n",
    "    # We're in an active loop, use await directly\n",
    "    result = await run_review()\n",
    "except RuntimeError:\n",
    "    # No running loop, create one (nbconvert case)\n",
    "    result = asyncio.run(run_review())\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìä CODE REVIEW RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for node_id in [\"security_check\", \"quality_check\", \"final_summary\"]:\n",
    "    if node_id in result and result[node_id]:\n",
    "        print(f\"\\n[{node_id.upper()}]:\")\n",
    "        print(\"-\" * 40)\n",
    "        output_val = result[node_id]\n",
    "        if isinstance(output_val, dict) and \"output\" in output_val:\n",
    "            print(output_val[\"output\"])\n",
    "        else:\n",
    "            print(output_val)\n",
    "\n",
    "print(\"\\n‚úÖ Review complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}
