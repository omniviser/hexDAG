{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Workflow - User Registration Pipeline\n",
    "\n",
    "This notebook demonstrates a real-world data processing pipeline that validates, enriches, scores, and formats user registration data.\n",
    "\n",
    "**What You'll Learn:**\n",
    "- Building practical data validation pipelines\n",
    "- Parallel processing with fan-out patterns\n",
    "- Multi-step data enrichment workflows\n",
    "- Combining results from parallel operations\n",
    "\n",
    "**Pipeline Steps:**\n",
    "1. **Validate** - Check required fields and data quality\n",
    "2. **Enrich** - Add location data and company info (parallel)\n",
    "3. **Score** - Calculate user quality score\n",
    "4. **Format** - Prepare final output for database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Scenario\n",
    "\n",
    "**Problem:**\n",
    "Your SaaS platform receives user registrations from multiple sources. Each registration needs to be:\n",
    "- Validated for completeness and correctness\n",
    "- Enriched with additional data (location, company info)\n",
    "- Scored for lead quality\n",
    "- Formatted for storage in your database\n",
    "\n",
    "**Requirements:**\n",
    "- Process registrations quickly (parallel enrichment)\n",
    "- Maintain data quality (validation)\n",
    "- Calculate lead scores for sales prioritization\n",
    "- Ensure consistent data format\n",
    "\n",
    "**Solution:**\n",
    "A hexDAG pipeline that orchestrates these steps with parallel execution where possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Imports\n",
    "\n",
    "Import the core hexDAG components for building and executing our pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from datetime import datetime\n",
    "\n",
    "from hexdag.kernel.domain.dag import DirectedGraph, NodeSpec\n",
    "from hexdag.kernel.orchestration.orchestrator import Orchestrator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Define Validation Function\n",
    "\n",
    "The first step validates incoming registration data for required fields and format correctness:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def validate_registration(input_data: dict) -> dict:\n",
    "    \"\"\"Validate user registration data.\n",
    "\n",
    "    Checks:\n",
    "    - Required fields present\n",
    "    - Email format valid\n",
    "    - Phone number format valid\n",
    "    \"\"\"\n",
    "    await asyncio.sleep(0.1)  # Simulate validation processing\n",
    "\n",
    "    warnings = []\n",
    "\n",
    "    # Check required fields\n",
    "    required = [\"email\", \"name\", \"company\"]\n",
    "    errors = [f\"Missing required field: {field}\" for field in required if not input_data.get(field)]\n",
    "\n",
    "    # Basic email validation\n",
    "    email = input_data.get(\"email\", \"\")\n",
    "    if email and \"@\" not in email:\n",
    "        errors.append(\"Invalid email format\")\n",
    "\n",
    "    # Check phone if provided\n",
    "    phone = input_data.get(\"phone\")\n",
    "    if phone and len(phone) < 10:\n",
    "        warnings.append(\"Phone number seems incomplete\")\n",
    "\n",
    "    return {\n",
    "        \"validated_data\": input_data,\n",
    "        \"is_valid\": len(errors) == 0,\n",
    "        \"errors\": errors,\n",
    "        \"warnings\": warnings,\n",
    "        \"validation_timestamp\": datetime.now().isoformat(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Define Location Enrichment Function\n",
    "\n",
    "Enriches registration data with geographic information based on phone number or email domain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def enrich_location(input_data: dict) -> dict:\n",
    "    \"\"\"Enrich with location data.\n",
    "\n",
    "    Simulates API call to location service.\n",
    "    Runs in parallel with company enrichment.\n",
    "    \"\"\"\n",
    "    await asyncio.sleep(0.2)  # Simulate API call\n",
    "\n",
    "    validated_data = input_data.get(\"validate_registration\", {}).get(\"validated_data\", {})\n",
    "    email = validated_data.get(\"email\", \"\")\n",
    "\n",
    "    # Simple location inference from email domain\n",
    "    if \".uk\" in email:\n",
    "        location = {\"country\": \"UK\", \"region\": \"Europe\", \"timezone\": \"GMT\"}\n",
    "    elif \".de\" in email:\n",
    "        location = {\"country\": \"Germany\", \"region\": \"Europe\", \"timezone\": \"CET\"}\n",
    "    elif \".jp\" in email:\n",
    "        location = {\"country\": \"Japan\", \"region\": \"Asia\", \"timezone\": \"JST\"}\n",
    "    else:\n",
    "        location = {\"country\": \"USA\", \"region\": \"North America\", \"timezone\": \"PST\"}\n",
    "\n",
    "    return {\"location_data\": location, \"enrichment_source\": \"location_api\", \"confidence\": 0.85}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Define Company Enrichment Function\n",
    "\n",
    "Enriches registration data with company information from external databases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def enrich_company(input_data: dict) -> dict:\n",
    "    \"\"\"Enrich with company data.\n",
    "\n",
    "    Simulates API call to company database.\n",
    "    Runs in parallel with location enrichment.\n",
    "    \"\"\"\n",
    "    await asyncio.sleep(0.25)  # Simulate database query\n",
    "\n",
    "    validated_data = input_data.get(\"validate_registration\", {}).get(\"validated_data\", {})\n",
    "    company = validated_data.get(\"company\", \"\")\n",
    "\n",
    "    # Simulate company data lookup\n",
    "    company_data = {\n",
    "        \"company_name\": company,\n",
    "        \"industry\": \"Technology\",\n",
    "        \"size\": \"50-200 employees\",\n",
    "        \"founded\": 2018,\n",
    "        \"is_verified\": True,\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        \"company_data\": company_data,\n",
    "        \"enrichment_source\": \"company_database\",\n",
    "        \"last_updated\": datetime.now().isoformat(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Define Scoring Function\n",
    "\n",
    "Calculates a lead quality score based on validation results and enrichment data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def calculate_score(input_data: dict) -> dict:\n",
    "    \"\"\"Calculate user quality score.\n",
    "\n",
    "    Scoring factors:\n",
    "    - Data completeness (30%)\n",
    "    - Company verification (40%)\n",
    "    - Location confidence (30%)\n",
    "    \"\"\"\n",
    "    await asyncio.sleep(0.1)  # Simulate scoring computation\n",
    "\n",
    "    # Extract data from dependencies\n",
    "    validation = input_data.get(\"validate_registration\", {})\n",
    "    location = input_data.get(\"enrich_location\", {})\n",
    "    company = input_data.get(\"enrich_company\", {})\n",
    "\n",
    "    score = 0\n",
    "    factors = {}\n",
    "\n",
    "    # Data completeness score (0-30 points)\n",
    "    validated_data = validation.get(\"validated_data\", {})\n",
    "    completeness = len([v for v in validated_data.values() if v]) / max(len(validated_data), 1)\n",
    "    completeness_score = completeness * 30\n",
    "    score += completeness_score\n",
    "    factors[\"completeness\"] = completeness_score\n",
    "\n",
    "    # Company verification score (0-40 points)\n",
    "    is_verified = company.get(\"company_data\", {}).get(\"is_verified\", False)\n",
    "    verification_score = 40 if is_verified else 10\n",
    "    score += verification_score\n",
    "    factors[\"verification\"] = verification_score\n",
    "\n",
    "    # Location confidence score (0-30 points)\n",
    "    confidence = location.get(\"confidence\", 0)\n",
    "    confidence_score = confidence * 30\n",
    "    score += confidence_score\n",
    "    factors[\"location_confidence\"] = confidence_score\n",
    "\n",
    "    # Determine quality tier\n",
    "    if score >= 80:\n",
    "        tier = \"premium\"\n",
    "    elif score >= 60:\n",
    "        tier = \"standard\"\n",
    "    else:\n",
    "        tier = \"basic\"\n",
    "\n",
    "    return {\n",
    "        \"quality_score\": round(score, 2),\n",
    "        \"quality_tier\": tier,\n",
    "        \"score_factors\": factors,\n",
    "        \"scored_at\": datetime.now().isoformat(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Define Formatting Function\n",
    "\n",
    "Formats all collected data into a consistent structure ready for database storage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def format_output(input_data: dict) -> dict:\n",
    "    \"\"\"Format final output for database storage.\n",
    "\n",
    "    Combines all pipeline results into a single structured record.\n",
    "    \"\"\"\n",
    "    await asyncio.sleep(0.05)  # Simulate formatting\n",
    "\n",
    "    # Extract all dependency results\n",
    "    validation = input_data.get(\"validate_registration\", {})\n",
    "    location = input_data.get(\"enrich_location\", {})\n",
    "    company = input_data.get(\"enrich_company\", {})\n",
    "    scoring = input_data.get(\"calculate_score\", {})\n",
    "\n",
    "    # Build final record\n",
    "    validated_data = validation.get(\"validated_data\", {})\n",
    "\n",
    "    final_record = {\n",
    "        \"user_info\": {\n",
    "            \"email\": validated_data.get(\"email\"),\n",
    "            \"name\": validated_data.get(\"name\"),\n",
    "            \"phone\": validated_data.get(\"phone\"),\n",
    "        },\n",
    "        \"company_info\": company.get(\"company_data\", {}),\n",
    "        \"location_info\": location.get(\"location_data\", {}),\n",
    "        \"quality\": {\n",
    "            \"score\": scoring.get(\"quality_score\"),\n",
    "            \"tier\": scoring.get(\"quality_tier\"),\n",
    "        },\n",
    "        \"validation\": {\n",
    "            \"is_valid\": validation.get(\"is_valid\"),\n",
    "            \"errors\": validation.get(\"errors\", []),\n",
    "            \"warnings\": validation.get(\"warnings\", []),\n",
    "        },\n",
    "        \"metadata\": {\n",
    "            \"processed_at\": datetime.now().isoformat(),\n",
    "            \"pipeline_version\": \"1.0.0\",\n",
    "            \"enrichment_sources\": [\n",
    "                location.get(\"enrichment_source\"),\n",
    "                company.get(\"enrichment_source\"),\n",
    "            ],\n",
    "        },\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        \"final_record\": final_record,\n",
    "        \"ready_for_storage\": validation.get(\"is_valid\", False),\n",
    "        \"processing_complete\": True,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Build the DAG\n",
    "\n",
    "Now we construct the directed acyclic graph that defines our pipeline structure:\n",
    "\n",
    "```\n",
    "validate_registration\n",
    "         |\n",
    "    +----+----+\n",
    "    |         |\n",
    "  location  company  (parallel enrichment)\n",
    "    |         |\n",
    "    +----+----+\n",
    "         |\n",
    "    calculate_score\n",
    "         |\n",
    "    format_output\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìä Building User Registration Pipeline...\")\n",
    "print()\n",
    "\n",
    "# Create the graph\n",
    "graph = DirectedGraph()\n",
    "\n",
    "# Wave 1: Validation (entry point)\n",
    "validate_node = NodeSpec(\"validate_registration\", validate_registration)\n",
    "graph += validate_node\n",
    "print(\"‚úÖ Wave 1: validate_registration\")\n",
    "\n",
    "# Wave 2: Parallel enrichment (fan-out pattern)\n",
    "location_node = NodeSpec(\"enrich_location\", enrich_location).after(\"validate_registration\")\n",
    "company_node = NodeSpec(\"enrich_company\", enrich_company).after(\"validate_registration\")\n",
    "\n",
    "graph += [location_node, company_node]\n",
    "print(\"‚úÖ Wave 2: enrich_location, enrich_company (PARALLEL)\")\n",
    "\n",
    "# Wave 3: Scoring (fan-in pattern)\n",
    "score_node = NodeSpec(\"calculate_score\", calculate_score).after(\n",
    "    \"validate_registration\", \"enrich_location\", \"enrich_company\"\n",
    ")\n",
    "graph += score_node\n",
    "print(\"‚úÖ Wave 3: calculate_score (waits for all enrichment)\")\n",
    "\n",
    "# Wave 4: Final formatting\n",
    "format_node = NodeSpec(\"format_output\", format_output).after(\n",
    "    \"validate_registration\", \"enrich_location\", \"enrich_company\", \"calculate_score\"\n",
    ")\n",
    "graph += format_node\n",
    "print(\"‚úÖ Wave 4: format_output (final step)\")\n",
    "\n",
    "print()\n",
    "print(\"üîç Validating pipeline structure...\")\n",
    "graph.validate()\n",
    "print(\"   ‚úÖ Pipeline validation passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Visualize Execution Waves\n",
    "\n",
    "Let's examine how the pipeline will execute in waves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üåä Execution Wave Analysis:\")\n",
    "print()\n",
    "waves = graph.waves()\n",
    "for i, wave in enumerate(waves, 1):\n",
    "    if len(wave) == 1:\n",
    "        print(f\"   Wave {i}: {wave[0]} (sequential)\")\n",
    "    else:\n",
    "        print(f\"   Wave {i}: {', '.join(wave)} (PARALLEL)\")\n",
    "\n",
    "print()\n",
    "print(f\"‚ö° Total waves: {len(waves)}\")\n",
    "print(f\"   üöÄ Wave 2 processes {len(waves[1])} nodes in parallel!\")\n",
    "print(\"   ‚è±Ô∏è  This reduces total execution time significantly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Prepare Sample Registration Data\n",
    "\n",
    "Create realistic test data representing a new user registration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample registration data\n",
    "sample_registration = {\n",
    "    \"email\": \"sarah.johnson@techstartup.uk\",\n",
    "    \"name\": \"Sarah Johnson\",\n",
    "    \"company\": \"TechStartup Ltd\",\n",
    "    \"phone\": \"+44-20-1234-5678\",\n",
    "    \"role\": \"Engineering Manager\",\n",
    "    \"source\": \"website_signup\",\n",
    "}\n",
    "\n",
    "print(\"üìù Sample Registration Data:\")\n",
    "print()\n",
    "for key, value in sample_registration.items():\n",
    "    print(f\"   {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Execute the Pipeline\n",
    "\n",
    "Run the complete pipeline with our sample data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "print(\"üöÄ Executing User Registration Pipeline...\")\n",
    "print()\n",
    "\n",
    "# Create orchestrator and execute\n",
    "orchestrator = Orchestrator()\n",
    "\n",
    "start_time = time.time()\n",
    "results = await orchestrator.run(graph, sample_registration)\n",
    "end_time = time.time()\n",
    "\n",
    "execution_time = end_time - start_time\n",
    "print(\"‚úÖ Pipeline execution complete!\")\n",
    "print(f\"‚è±Ô∏è  Total time: {execution_time:.3f} seconds\")\n",
    "print()\n",
    "print(\"   Note: Parallel enrichment (Wave 2) saved significant time!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Examine Validation Results\n",
    "\n",
    "Let's look at the validation step output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_result = results[\"validate_registration\"]\n",
    "\n",
    "print(\"üîç Validation Results:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Is Valid: {validation_result['is_valid']}\")\n",
    "print(f\"Errors: {validation_result['errors'] if validation_result['errors'] else 'None'}\")\n",
    "print(f\"Warnings: {validation_result['warnings'] if validation_result['warnings'] else 'None'}\")\n",
    "print(f\"Timestamp: {validation_result['validation_timestamp']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 12: Examine Enrichment Results\n",
    "\n",
    "View the parallel enrichment data (location and company):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_result = results[\"enrich_location\"]\n",
    "company_result = results[\"enrich_company\"]\n",
    "\n",
    "print(\"üåç Location Enrichment:\")\n",
    "print(\"=\" * 60)\n",
    "for key, value in location_result[\"location_data\"].items():\n",
    "    print(f\"{key}: {value}\")\n",
    "print(f\"Confidence: {location_result['confidence']}\")\n",
    "print()\n",
    "\n",
    "print(\"üè¢ Company Enrichment:\")\n",
    "print(\"=\" * 60)\n",
    "for key, value in company_result[\"company_data\"].items():\n",
    "    print(f\"{key}: {value}\")\n",
    "print()\n",
    "print(\"üí° These two enrichments ran in parallel (Wave 2)!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 13: Examine Scoring Results\n",
    "\n",
    "View the calculated quality score and breakdown:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_result = results[\"calculate_score\"]\n",
    "\n",
    "print(\"üìä Quality Scoring:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Overall Score: {score_result['quality_score']}/100\")\n",
    "print(f\"Quality Tier: {score_result['quality_tier'].upper()}\")\n",
    "print()\n",
    "print(\"Score Breakdown:\")\n",
    "for factor, value in score_result[\"score_factors\"].items():\n",
    "    print(f\"  {factor}: {value:.2f} points\")\n",
    "print()\n",
    "print(f\"Scored at: {score_result['scored_at']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 14: View Final Formatted Output\n",
    "\n",
    "This is the complete, structured record ready for database storage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result = results[\"format_output\"]\n",
    "\n",
    "print(\"üì¶ Final Formatted Record:\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "record = final_result[\"final_record\"]\n",
    "\n",
    "print(\"üë§ User Info:\")\n",
    "for key, value in record[\"user_info\"].items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "print()\n",
    "\n",
    "print(\"üè¢ Company Info:\")\n",
    "for key, value in record[\"company_info\"].items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "print()\n",
    "\n",
    "print(\"üåç Location Info:\")\n",
    "for key, value in record[\"location_info\"].items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "print()\n",
    "\n",
    "print(\"‚≠ê Quality:\")\n",
    "for key, value in record[\"quality\"].items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "print()\n",
    "\n",
    "print(f\"Ready for Storage: {final_result['ready_for_storage']}\")\n",
    "print(f\"Processing Complete: {final_result['processing_complete']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 15: Test with Invalid Data\n",
    "\n",
    "Let's see how the pipeline handles incomplete registration data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incomplete registration - missing company\n",
    "invalid_registration = {\n",
    "    \"email\": \"incomplete-user\",  # Invalid format\n",
    "    \"name\": \"Test User\",\n",
    "    # Missing: company\n",
    "    \"phone\": \"123\",  # Too short\n",
    "}\n",
    "\n",
    "print(\"üî¥ Testing with Invalid Data:\")\n",
    "print()\n",
    "for key, value in invalid_registration.items():\n",
    "    print(f\"   {key}: {value}\")\n",
    "\n",
    "print()\n",
    "print(\"üöÄ Executing pipeline...\")\n",
    "invalid_results = await orchestrator.run(graph, invalid_registration)\n",
    "print(\"   ‚úÖ Execution complete (with validation errors)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 16: View Validation Errors\n",
    "\n",
    "Examine how validation caught the data quality issues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_validation = invalid_results[\"validate_registration\"]\n",
    "invalid_final = invalid_results[\"format_output\"]\n",
    "\n",
    "print(\"‚ùå Validation Issues Found:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Is Valid: {invalid_validation['is_valid']}\")\n",
    "print()\n",
    "\n",
    "if invalid_validation[\"errors\"]:\n",
    "    print(\"Errors:\")\n",
    "    for error in invalid_validation[\"errors\"]:\n",
    "        print(f\"  - {error}\")\n",
    "print()\n",
    "\n",
    "if invalid_validation[\"warnings\"]:\n",
    "    print(\"Warnings:\")\n",
    "    for warning in invalid_validation[\"warnings\"]:\n",
    "        print(f\"  - {warning}\")\n",
    "print()\n",
    "\n",
    "print(f\"Ready for Storage: {invalid_final['ready_for_storage']}\")\n",
    "print()\n",
    "print(\"üí° Pipeline processed the data but flagged it as invalid!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 17: Compare Quality Scores\n",
    "\n",
    "See how data quality affects the calculated score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_score = results[\"calculate_score\"]\n",
    "invalid_score = invalid_results[\"calculate_score\"]\n",
    "\n",
    "print(\"üìä Quality Score Comparison:\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "print(\"‚úÖ Valid Registration:\")\n",
    "print(f\"   Score: {valid_score['quality_score']}/100\")\n",
    "print(f\"   Tier: {valid_score['quality_tier'].upper()}\")\n",
    "print()\n",
    "\n",
    "print(\"‚ùå Invalid Registration:\")\n",
    "print(f\"   Score: {invalid_score['quality_score']}/100\")\n",
    "print(f\"   Tier: {invalid_score['quality_tier'].upper()}\")\n",
    "print()\n",
    "\n",
    "score_diff = valid_score[\"quality_score\"] - invalid_score[\"quality_score\"]\n",
    "print(f\"üìâ Score difference: {score_diff:.2f} points\")\n",
    "print()\n",
    "print(\"üí° Data quality directly impacts lead scoring!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 18: Performance Analysis\n",
    "\n",
    "Understand the performance benefits of parallel execution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"‚ö° Performance Analysis:\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "# Simulated timings from our async sleep calls\n",
    "sequential_time = 0.1 + 0.2 + 0.25 + 0.1 + 0.05  # All steps sequential\n",
    "parallel_time = 0.1 + max(0.2, 0.25) + 0.1 + 0.05  # Enrichment in parallel\n",
    "\n",
    "print(f\"If executed sequentially: ~{sequential_time:.2f}s\")\n",
    "print(f\"With parallel enrichment: ~{parallel_time:.2f}s\")\n",
    "print()\n",
    "\n",
    "speedup = (sequential_time / parallel_time - 1) * 100\n",
    "print(f\"‚ö° Speedup: ~{speedup:.1f}% faster\")\n",
    "print()\n",
    "\n",
    "print(\"üåä Execution Wave Breakdown:\")\n",
    "print(\"   Wave 1: validate_registration (0.1s)\")\n",
    "print(\"   Wave 2: enrich_location + enrich_company (0.25s parallel)\")\n",
    "print(\"   Wave 3: calculate_score (0.1s)\")\n",
    "print(\"   Wave 4: format_output (0.05s)\")\n",
    "print()\n",
    "print(\"üí° Parallel execution in Wave 2 saves time!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 19: Examine Pipeline Metadata\n",
    "\n",
    "Review the processing metadata included in the final output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = results[\"format_output\"][\"final_record\"][\"metadata\"]\n",
    "\n",
    "print(\"üìã Pipeline Metadata:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Processed At: {metadata['processed_at']}\")\n",
    "print(f\"Pipeline Version: {metadata['pipeline_version']}\")\n",
    "print()\n",
    "print(\"Enrichment Sources:\")\n",
    "for source in metadata[\"enrichment_sources\"]:\n",
    "    print(f\"  - {source}\")\n",
    "print()\n",
    "print(\"üí° Metadata enables audit trails and debugging!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 20: Summary and Key Takeaways\n",
    "\n",
    "Review what we've learned from this practical pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üéØ Key Concepts Demonstrated:\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "print(\"‚úÖ Pipeline Patterns:\")\n",
    "print(\"   ‚Ä¢ Sequential validation before enrichment\")\n",
    "print(\"   ‚Ä¢ Fan-out: One validation ‚Üí Multiple parallel enrichments\")\n",
    "print(\"   ‚Ä¢ Fan-in: Multiple enrichments ‚Üí Single scoring step\")\n",
    "print(\"   ‚Ä¢ Final aggregation: All results ‚Üí Formatted output\")\n",
    "print()\n",
    "\n",
    "print(\"‚úÖ Parallel Execution:\")\n",
    "print(\"   ‚Ä¢ Location and company enrichment run simultaneously\")\n",
    "print(\"   ‚Ä¢ Reduces total pipeline execution time\")\n",
    "print(\"   ‚Ä¢ Wave-based execution for optimal performance\")\n",
    "print()\n",
    "\n",
    "print(\"‚úÖ Data Quality:\")\n",
    "print(\"   ‚Ä¢ Validation catches errors early\")\n",
    "print(\"   ‚Ä¢ Quality scoring prioritizes leads\")\n",
    "print(\"   ‚Ä¢ Pipeline processes both valid and invalid data\")\n",
    "print()\n",
    "\n",
    "print(\"‚úÖ Real-World Features:\")\n",
    "print(\"   ‚Ä¢ Metadata for audit trails\")\n",
    "print(\"   ‚Ä¢ Structured output for database storage\")\n",
    "print(\"   ‚Ä¢ Error handling and warnings\")\n",
    "print(\"   ‚Ä¢ Multi-source data enrichment\")\n",
    "print()\n",
    "\n",
    "print(\"üîó Next Steps:\")\n",
    "print(\"   ‚Ä¢ Add conditional logic (e.g., skip enrichment if invalid)\")\n",
    "print(\"   ‚Ä¢ Integrate with real APIs (location, company databases)\")\n",
    "print(\"   ‚Ä¢ Add retry logic for failed enrichments\")\n",
    "print(\"   ‚Ä¢ Convert to YAML pipeline for declarative configuration\")\n",
    "print(\"   ‚Ä¢ Add LLM-based data extraction or classification\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}
