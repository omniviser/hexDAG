{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“¦ YAML Includes & Pipeline Composition\n",
    "\n",
    "Learn how to build modular, reusable YAML pipelines using the `!include` directive:\n",
    "\n",
    "- **Modular workflows** - Break large pipelines into reusable components\n",
    "- **DRY principle** - Don't Repeat Yourself with shared configurations\n",
    "- **Team collaboration** - Share common nodes across projects\n",
    "- **Environment configs** - Different settings per environment (dev/staging/prod)\n",
    "- **Security** - Built-in protection against directory traversal and circular includes\n",
    "\n",
    "The `!include` directive enables composition patterns similar to Kubernetes ConfigMaps and Helm values files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Use YAML Includes?\n",
    "\n",
    "**Without Includes:**\n",
    "```yaml\n",
    "# pipeline-a.yaml - 200 lines\n",
    "nodes:\n",
    "  - common_node_1: { ... 20 lines ... }\n",
    "  - common_node_2: { ... 20 lines ... }\n",
    "  - specific_node_a: { ... }\n",
    "\n",
    "# pipeline-b.yaml - 200 lines  \n",
    "nodes:\n",
    "  - common_node_1: { ... 20 lines DUPLICATED ... }\n",
    "  - common_node_2: { ... 20 lines DUPLICATED ... }\n",
    "  - specific_node_b: { ... }\n",
    "```\n",
    "\n",
    "**With Includes:**\n",
    "```yaml\n",
    "# common-nodes.yaml - 40 lines\n",
    "common_nodes: &common\n",
    "  - common_node_1: { ... 20 lines ... }\n",
    "  - common_node_2: { ... 20 lines ... }\n",
    "\n",
    "# pipeline-a.yaml - 10 lines\n",
    "nodes:\n",
    "  - !include common-nodes.yaml#common\n",
    "  - specific_node_a: { ... }\n",
    "\n",
    "# pipeline-b.yaml - 10 lines\n",
    "nodes:\n",
    "  - !include common-nodes.yaml#common\n",
    "  - specific_node_b: { ... }\n",
    "```\n",
    "\n",
    "**Benefits:**\n",
    "- âœ… **90% less duplication** - Single source of truth\n",
    "- âœ… **Easier maintenance** - Update once, affects all pipelines\n",
    "- âœ… **Better organization** - Logical separation of concerns\n",
    "- âœ… **Team scalability** - Teams can share component libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Create Temporary Directory Structure\n",
    "\n",
    "We'll create a realistic project structure with shared components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "# Create temporary directory for our examples\n",
    "temp_dir = Path(tempfile.mkdtemp())\n",
    "print(f\"ğŸ“ Working directory: {temp_dir}\")\n",
    "\n",
    "# Create project structure\n",
    "(temp_dir / \"shared\").mkdir()\n",
    "(temp_dir / \"pipelines\").mkdir()\n",
    "(temp_dir / \"environments\").mkdir()\n",
    "\n",
    "# Create helper functions file for examples\n",
    "helper_functions = '''\n",
    "\"\"\"Helper functions for YAML include examples.\"\"\"\n",
    "\n",
    "def validate_string(data: str) -> str:\n",
    "    \"\"\"Validate that input is a string.\"\"\"\n",
    "    return str(data)\n",
    "\n",
    "def clean_whitespace(data: str) -> str:\n",
    "    \"\"\"Remove leading/trailing whitespace.\"\"\"\n",
    "    return data.strip()\n",
    "\n",
    "def to_uppercase(data: str) -> str:\n",
    "    \"\"\"Convert string to uppercase.\"\"\"\n",
    "    return data.upper()\n",
    "\n",
    "def to_lowercase(data: str) -> str:\n",
    "    \"\"\"Convert string to lowercase.\"\"\"\n",
    "    return data.lower()\n",
    "\n",
    "def calculate_length(data: str) -> int:\n",
    "    \"\"\"Calculate string length.\"\"\"\n",
    "    return len(data)\n",
    "'''\n",
    "\n",
    "(temp_dir / \"helpers.py\").write_text(helper_functions)\n",
    "\n",
    "# Add temp_dir to Python path so we can import helpers\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, str(temp_dir))\n",
    "\n",
    "print(\"\\nâœ… Directory structure created:\")\n",
    "print(\"   shared/       - Reusable components\")\n",
    "print(\"   pipelines/    - Main pipeline definitions\")\n",
    "print(\"   environments/ - Environment-specific configs\")\n",
    "print(\"   helpers.py    - Helper functions for examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Simple Include - Shared Nodes\n",
    "\n",
    "The most common pattern: extracting reusable nodes into a shared file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create shared nodes file\n",
    "shared_nodes_yaml = \"\"\"\n",
    "# Common validation and preprocessing nodes\n",
    "validation_nodes:\n",
    "  - kind: function_node\n",
    "    metadata:\n",
    "      name: input_validator\n",
    "    spec:\n",
    "      fn: \"helpers.validate_string\"\n",
    "      dependencies: []\n",
    "\n",
    "  - kind: function_node\n",
    "    metadata:\n",
    "      name: data_cleaner\n",
    "    spec:\n",
    "      fn: \"helpers.clean_whitespace\"\n",
    "      dependencies: [input_validator]\n",
    "\"\"\"\n",
    "\n",
    "(temp_dir / \"shared\" / \"common-nodes.yaml\").write_text(shared_nodes_yaml)\n",
    "print(\"âœ… Created: shared/common-nodes.yaml\")\n",
    "print(\"\\nğŸ“„ Contents:\")\n",
    "print(shared_nodes_yaml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline that includes shared nodes\n",
    "# When including a list into a list, the !include should be a list item\n",
    "pipeline_with_include = \"\"\"\n",
    "apiVersion: hexdag/v1\n",
    "kind: Pipeline\n",
    "metadata:\n",
    "  name: text-processor\n",
    "  description: Process text using shared validation nodes\n",
    "spec:\n",
    "  # The !include will expand to a list of nodes\n",
    "  nodes: {\"!include\": \"shared/common-nodes.yaml#validation_nodes\"}\n",
    "\"\"\"\n",
    "\n",
    "(temp_dir / \"pipelines\" / \"text-processor.yaml\").write_text(pipeline_with_include)\n",
    "\n",
    "# Also copy shared nodes to pipelines/shared for this example\n",
    "(temp_dir / \"pipelines\" / \"shared\").mkdir()\n",
    "import shutil\n",
    "\n",
    "shutil.copy(\n",
    "    temp_dir / \"shared\" / \"common-nodes.yaml\",\n",
    "    temp_dir / \"pipelines\" / \"shared\" / \"common-nodes.yaml\",\n",
    ")\n",
    "\n",
    "print(\"âœ… Created: pipelines/text-processor.yaml\")\n",
    "print(\"âœ… Copied: shared/common-nodes.yaml â†’ pipelines/shared/common-nodes.yaml\")\n",
    "print(\"\\nğŸ“„ Pipeline Contents:\")\n",
    "print(pipeline_with_include)\n",
    "print(\"\\nğŸ’¡ The !include directive will expand to the full list of validation nodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute Pipeline With Includes\n",
    "\n",
    "The builder automatically resolves `!include` directives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hexdag.core.orchestration.orchestrator import Orchestrator\n",
    "from hexdag.core.pipeline_builder.yaml_builder import YamlPipelineBuilder\n",
    "\n",
    "# Build pipeline (includes are automatically resolved)\n",
    "# Note: build_from_yaml_file() automatically sets base_path to the YAML file's directory\n",
    "builder = YamlPipelineBuilder(base_path=temp_dir)\n",
    "graph, config = builder.build_from_yaml_file(str(temp_dir / \"pipelines\" / \"text-processor.yaml\"))\n",
    "\n",
    "print(\"ğŸ—ï¸  Pipeline built successfully!\")\n",
    "print(f\"   Nodes: {list(graph.nodes.keys())}\")\n",
    "print(f\"   Total nodes: {len(graph.nodes)}\")\n",
    "print(\"\\nğŸ’¡ Notice: Included nodes (input_validator, data_cleaner) are merged seamlessly!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the pipeline\n",
    "orchestrator = Orchestrator()\n",
    "result = await orchestrator.run(graph, \"  hello world  \")\n",
    "\n",
    "print(\"ğŸ“Š Execution Results:\")\n",
    "print(\"   Input: '  hello world  '\")\n",
    "print(f\"   After validation: '{result.get('input_validator')}'\")\n",
    "print(f\"   After cleaning: '{result.get('data_cleaner')}'\")\n",
    "print(f\"   Final output: '{result.get('text_processor')}'\")\n",
    "print(\"\\nâœ… Include directive successfully resolved and executed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Nested Includes - Multi-Level Composition\n",
    "\n",
    "Includes can reference other files with includes, enabling hierarchical composition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Level 1: Base validation (create in pipelines/shared/)\n",
    "base_validation = \"\"\"\n",
    "base_validators:\n",
    "  - kind: function_node\n",
    "    metadata:\n",
    "      name: type_checker\n",
    "    spec:\n",
    "      fn: \"helpers.to_lowercase\"\n",
    "      dependencies: []\n",
    "\"\"\"\n",
    "\n",
    "(temp_dir / \"pipelines\" / \"shared\" / \"base-validation.yaml\").write_text(base_validation)\n",
    "print(\"âœ… Created: pipelines/shared/base-validation.yaml (Level 1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Level 2: Extended validation (includes base, stays in shared/)\n",
    "extended_validation = \"\"\"\n",
    "extended_validators:\n",
    "  - {\"!include\": \"base-validation.yaml#base_validators\"}\n",
    "  \n",
    "  # Add extended validation\n",
    "  - kind: function_node\n",
    "    metadata:\n",
    "      name: length_checker\n",
    "    spec:\n",
    "      fn: \"helpers.calculate_length\"\n",
    "      dependencies: [type_checker]\n",
    "\"\"\"\n",
    "\n",
    "(temp_dir / \"pipelines\" / \"shared\" / \"extended-validation.yaml\").write_text(extended_validation)\n",
    "print(\"âœ… Created: pipelines/shared/extended-validation.yaml (Level 2 - includes Level 1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Level 3: Final pipeline (includes extended, relative to pipelines/)\n",
    "nested_pipeline = \"\"\"\n",
    "apiVersion: hexdag/v1\n",
    "kind: Pipeline\n",
    "metadata:\n",
    "  name: nested-validation\n",
    "  description: Pipeline with nested includes\n",
    "spec:\n",
    "  nodes:\n",
    "    - {\"!include\": \"shared/extended-validation.yaml#extended_validators\"}\n",
    "    \n",
    "    # Add final processing - depends on type_checker from level 1\n",
    "    - kind: function_node\n",
    "      metadata:\n",
    "        name: result_formatter\n",
    "      spec:\n",
    "        fn: \"helpers.to_uppercase\"\n",
    "        dependencies: [type_checker]\n",
    "\"\"\"\n",
    "\n",
    "(temp_dir / \"pipelines\" / \"nested-validation.yaml\").write_text(nested_pipeline)\n",
    "print(\"âœ… Created: pipelines/nested-validation.yaml (Level 3 - includes Level 2)\")\n",
    "print(\"\\nğŸ”— Include Chain:\")\n",
    "print(\"   pipelines/nested-validation.yaml\")\n",
    "print(\"   â””â”€â”€ includes: shared/extended-validation.yaml\")\n",
    "print(\"       â””â”€â”€ includes: shared/base-validation.yaml\")\n",
    "print(\"\\nğŸ’¡ All files are within pipelines/ directory - no security violations!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and verify nested includes work\n",
    "builder = YamlPipelineBuilder(base_path=temp_dir)\n",
    "graph, config = builder.build_from_yaml_file(str(temp_dir / \"pipelines\" / \"nested-validation.yaml\"))\n",
    "\n",
    "print(\"ğŸ—ï¸  Nested includes resolved successfully!\")\n",
    "print(f\"   Total nodes: {len(graph.nodes)}\")\n",
    "print(f\"   Node chain: {list(graph.nodes.keys())}\")\n",
    "print(\"\\nâœ… All 3 levels of includes merged correctly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Environment-Specific Configs\n",
    "\n",
    "Use includes to maintain environment-specific settings (dev/staging/prod):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shared pipeline structure\n",
    "base_pipeline = \"\"\"\n",
    "base_nodes:\n",
    "  - kind: function_node\n",
    "    metadata:\n",
    "      name: processor\n",
    "    spec:\n",
    "      fn: \"helpers.to_uppercase\"\n",
    "      dependencies: []\n",
    "\"\"\"\n",
    "\n",
    "(temp_dir / \"shared\" / \"base-pipeline.yaml\").write_text(base_pipeline)\n",
    "print(\"âœ… Created: shared/base-pipeline.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Development environment config\n",
    "dev_config = \"\"\"\n",
    "apiVersion: hexdag/v1\n",
    "kind: Pipeline\n",
    "metadata:\n",
    "  name: app-pipeline\n",
    "  namespace: development\n",
    "  description: Development environment - verbose logging\n",
    "spec:\n",
    "  nodes:\n",
    "    - {\"!include\": \"../shared/base-pipeline.yaml#base_nodes\"}\n",
    "  \n",
    "  # Dev-specific: Add debug logging\n",
    "  policies:\n",
    "    logging:\n",
    "      level: DEBUG\n",
    "      verbose: true\n",
    "\"\"\"\n",
    "\n",
    "(temp_dir / \"environments\" / \"dev.yaml\").write_text(dev_config)\n",
    "print(\"âœ… Created: environments/dev.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Production environment config\n",
    "prod_config = \"\"\"\n",
    "apiVersion: hexdag/v1\n",
    "kind: Pipeline\n",
    "metadata:\n",
    "  name: app-pipeline\n",
    "  namespace: production\n",
    "  description: Production environment - minimal logging\n",
    "spec:\n",
    "  nodes:\n",
    "    - {\"!include\": \"../shared/base-pipeline.yaml#base_nodes\"}\n",
    "  \n",
    "  # Prod-specific: Minimal logging, monitoring enabled\n",
    "  policies:\n",
    "    logging:\n",
    "      level: ERROR\n",
    "      verbose: false\n",
    "    monitoring:\n",
    "      enabled: true\n",
    "      alerts: true\n",
    "\"\"\"\n",
    "\n",
    "(temp_dir / \"environments\" / \"prod.yaml\").write_text(prod_config)\n",
    "print(\"âœ… Created: environments/prod.yaml\")\n",
    "print(\"\\nğŸ’¡ Same base pipeline, different environment configs!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load development config\n",
    "builder = YamlPipelineBuilder(base_path=temp_dir)\n",
    "graph_dev, config_dev = builder.build_from_yaml_file(str(temp_dir / \"environments\" / \"dev.yaml\"))\n",
    "\n",
    "print(\"ğŸ”§ Development Environment:\")\n",
    "print(f\"   Namespace: {config_dev.metadata.get('namespace')}\")\n",
    "print(f\"   Logging level: {config_dev.policies.get('logging', {}).get('level')}\")\n",
    "print(f\"   Verbose: {config_dev.policies.get('logging', {}).get('verbose')}\")\n",
    "print(f\"   Nodes: {list(graph_dev.nodes.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load production config\n",
    "graph_prod, config_prod = builder.build_from_yaml_file(str(temp_dir / \"environments\" / \"prod.yaml\"))\n",
    "\n",
    "print(\"ğŸš€ Production Environment:\")\n",
    "print(f\"   Namespace: {config_prod.metadata.get('namespace')}\")\n",
    "print(f\"   Logging level: {config_prod.policies.get('logging', {}).get('level')}\")\n",
    "print(f\"   Monitoring: {config_prod.policies.get('monitoring', {}).get('enabled')}\")\n",
    "print(f\"   Nodes: {list(graph_prod.nodes.keys())}\")\n",
    "print(\"\\nâœ… Same pipeline structure, different configurations!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: Security Features\n",
    "\n",
    "The include system has built-in security protections:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4a. Circular Include Detection\n",
    "\n",
    "Prevents infinite loops from circular references:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create circular reference\n",
    "circular_a = \"\"\"\n",
    "nodes_a: &a\n",
    "  - {\"!include\": \"circular-b.yaml#nodes_b\"}\n",
    "\"\"\"\n",
    "\n",
    "circular_b = \"\"\"\n",
    "nodes_b: &b\n",
    "  - {\"!include\": \"circular-a.yaml#nodes_a\"}\n",
    "\"\"\"\n",
    "\n",
    "(temp_dir / \"shared\" / \"circular-a.yaml\").write_text(circular_a)\n",
    "(temp_dir / \"shared\" / \"circular-b.yaml\").write_text(circular_b)\n",
    "\n",
    "print(\"âœ… Created circular reference files\")\n",
    "print(\"   circular-a.yaml â†’ circular-b.yaml\")\n",
    "print(\"   circular-b.yaml â†’ circular-a.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to build pipeline with circular include\n",
    "circular_pipeline = \"\"\"\n",
    "apiVersion: hexdag/v1\n",
    "kind: Pipeline\n",
    "metadata:\n",
    "  name: circular-test\n",
    "spec:\n",
    "  nodes:\n",
    "    - {\"!include\": \"../shared/circular-a.yaml#nodes_a\"}\n",
    "\"\"\"\n",
    "\n",
    "(temp_dir / \"pipelines\" / \"circular-test.yaml\").write_text(circular_pipeline)\n",
    "\n",
    "try:\n",
    "    builder = YamlPipelineBuilder(base_path=temp_dir)\n",
    "    graph, config = builder.build_from_yaml_file(str(temp_dir / \"pipelines\" / \"circular-test.yaml\"))\n",
    "    print(\"âŒ Should have detected circular include!\")\n",
    "except Exception as e:\n",
    "    print(\"âœ… Circular include detected and prevented!\")\n",
    "    print(f\"   Error: {type(e).__name__}\")\n",
    "    print(f\"   Message: {str(e)[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4b. Directory Traversal Protection\n",
    "\n",
    "Prevents malicious paths from accessing files outside the project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to access file outside project directory\n",
    "malicious_pipeline = \"\"\"\n",
    "apiVersion: hexdag/v1\n",
    "kind: Pipeline\n",
    "metadata:\n",
    "  name: malicious-test\n",
    "spec:\n",
    "  nodes:\n",
    "    # Try to traverse outside project\n",
    "    - {\"!include\": \"../../../../etc/passwd\"}\n",
    "\"\"\"\n",
    "\n",
    "(temp_dir / \"pipelines\" / \"malicious-test.yaml\").write_text(malicious_pipeline)\n",
    "\n",
    "try:\n",
    "    builder = YamlPipelineBuilder(base_path=temp_dir)\n",
    "    graph, config = builder.build_from_yaml_file(\n",
    "        str(temp_dir / \"pipelines\" / \"malicious-test.yaml\")\n",
    "    )\n",
    "    print(\"âŒ Should have blocked directory traversal!\")\n",
    "except Exception as e:\n",
    "    print(\"âœ… Directory traversal blocked!\")\n",
    "    print(f\"   Error: {type(e).__name__}\")\n",
    "    print(f\"   Message: {str(e)[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4c. Absolute Path Rejection\n",
    "\n",
    "Only relative paths are allowed for security:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to use absolute path\n",
    "absolute_pipeline = \"\"\"\n",
    "apiVersion: hexdag/v1\n",
    "kind: Pipeline\n",
    "metadata:\n",
    "  name: absolute-test\n",
    "spec:\n",
    "  nodes:\n",
    "    - {\"!include\": \"/absolute/path/to/file.yaml\"}\n",
    "\"\"\"\n",
    "\n",
    "(temp_dir / \"pipelines\" / \"absolute-test.yaml\").write_text(absolute_pipeline)\n",
    "\n",
    "try:\n",
    "    builder = YamlPipelineBuilder(base_path=temp_dir)\n",
    "    graph, config = builder.build_from_yaml_file(str(temp_dir / \"pipelines\" / \"absolute-test.yaml\"))\n",
    "    print(\"âŒ Should have rejected absolute path!\")\n",
    "except Exception as e:\n",
    "    print(\"âœ… Absolute path rejected!\")\n",
    "    print(f\"   Error: {type(e).__name__}\")\n",
    "    print(f\"   Message: {str(e)[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5: Real-World Pattern - Component Library\n",
    "\n",
    "Build a reusable component library for your organization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create component library structure within pipelines directory\n",
    "(temp_dir / \"pipelines\" / \"components\").mkdir()\n",
    "(temp_dir / \"pipelines\" / \"components\" / \"validation\").mkdir()\n",
    "(temp_dir / \"pipelines\" / \"components\" / \"processing\").mkdir()\n",
    "(temp_dir / \"pipelines\" / \"components\" / \"output\").mkdir()\n",
    "\n",
    "print(\"ğŸ“š Component Library Structure:\")\n",
    "print(\"   pipelines/\")\n",
    "print(\"   â””â”€â”€ components/\")\n",
    "print(\"       â”œâ”€â”€ validation/  - Input validation components\")\n",
    "print(\"       â”œâ”€â”€ processing/  - Data processing components\")\n",
    "print(\"       â””â”€â”€ output/      - Output formatting components\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation component\n",
    "validation_component = \"\"\"\n",
    "string_validators:\n",
    "  - kind: function_node\n",
    "    metadata:\n",
    "      name: string_validator\n",
    "    spec:\n",
    "      fn: \"helpers.validate_string\"\n",
    "      dependencies: []\n",
    "  \n",
    "  - kind: function_node\n",
    "    metadata:\n",
    "      name: trim_whitespace\n",
    "    spec:\n",
    "      fn: \"helpers.clean_whitespace\"\n",
    "      dependencies: [string_validator]\n",
    "\"\"\"\n",
    "\n",
    "(temp_dir / \"pipelines\" / \"components\" / \"validation\" / \"string-validation.yaml\").write_text(\n",
    "    validation_component\n",
    ")\n",
    "print(\"âœ… Created: pipelines/components/validation/string-validation.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing component\n",
    "processing_component = \"\"\"\n",
    "text_processors: &processors\n",
    "  - kind: function_node\n",
    "    metadata:\n",
    "      name: to_uppercase\n",
    "    spec:\n",
    "      fn: \"str.upper\"\n",
    "    dependencies: []\n",
    "  \n",
    "  - kind: function_node\n",
    "    metadata:\n",
    "      name: get_length\n",
    "    spec:\n",
    "      fn: \"builtins.len\"\n",
    "    dependencies: []\n",
    "\"\"\"\n",
    "\n",
    "(temp_dir / \"pipelines\" / \"components\" / \"processing\" / \"text-processing.yaml\").write_text(\n",
    "    processing_component\n",
    ")\n",
    "print(\"âœ… Created: pipelines/components/processing/text-processing.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output component\n",
    "output_component = \"\"\"\n",
    "formatters:\n",
    "  - kind: function_node\n",
    "    metadata:\n",
    "      name: format_output\n",
    "    spec:\n",
    "      fn: \"helpers.to_uppercase\"\n",
    "      dependencies: []\n",
    "\"\"\"\n",
    "\n",
    "(temp_dir / \"pipelines\" / \"components\" / \"output\" / \"formatters.yaml\").write_text(output_component)\n",
    "print(\"âœ… Created: pipelines/components/output/formatters.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compose pipeline from component library\n",
    "composed_pipeline = \"\"\"\n",
    "apiVersion: hexdag/v1\n",
    "kind: Pipeline\n",
    "metadata:\n",
    "  name: composed-from-library\n",
    "  description: Pipeline composed from reusable components\n",
    "spec:\n",
    "  nodes:\n",
    "    # Import validation components\n",
    "    - {\"!include\": \"components/validation/string-validation.yaml#string_validators\"}\n",
    "    \n",
    "    # Import processing components  \n",
    "    - kind: function_node\n",
    "      metadata:\n",
    "        name: process_text\n",
    "      spec:\n",
    "        fn: \"helpers.to_uppercase\"\n",
    "        dependencies: [trim_whitespace]\n",
    "    \n",
    "    # Import output components\n",
    "    - kind: function_node\n",
    "      metadata:\n",
    "        name: final_output\n",
    "      spec:\n",
    "        fn: \"helpers.validate_string\"\n",
    "        dependencies: [process_text]\n",
    "\"\"\"\n",
    "\n",
    "(temp_dir / \"pipelines\" / \"composed-pipeline.yaml\").write_text(composed_pipeline)\n",
    "print(\"âœ… Created: pipelines/composed-pipeline.yaml\")\n",
    "print(\"\\nğŸ”§ Pipeline composed from component library!\")\n",
    "print(\"   All includes are relative to pipelines/ directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and execute composed pipeline\n",
    "builder = YamlPipelineBuilder(base_path=temp_dir)\n",
    "graph, config = builder.build_from_yaml_file(str(temp_dir / \"pipelines\" / \"composed-pipeline.yaml\"))\n",
    "\n",
    "print(\"ğŸ—ï¸  Composed Pipeline Built:\")\n",
    "print(f\"   Total nodes: {len(graph.nodes)}\")\n",
    "print(f\"   Nodes: {list(graph.nodes.keys())}\")\n",
    "print(\"\\nğŸ“Š Component Sources:\")\n",
    "print(\"   â€¢ string_validator, trim_whitespace â†’ validation/string-validation.yaml\")\n",
    "print(\"   â€¢ process_text â†’ defined inline\")\n",
    "print(\"   â€¢ final_output â†’ defined inline\")\n",
    "\n",
    "# Execute\n",
    "orchestrator = Orchestrator()\n",
    "result = await orchestrator.run(graph, \"  test input  \")\n",
    "\n",
    "print(\"\\nâœ… Execution Complete:\")\n",
    "print(\"   Input: '  test input  '\")\n",
    "print(f\"   Final output: '{result.get('final_output')}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.rmtree(temp_dir)\n",
    "print(f\"ğŸ§¹ Cleaned up temporary directory: {temp_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: YAML Include Best Practices\n",
    "\n",
    "### âœ… When to Use Includes\n",
    "\n",
    "**Good Use Cases:**\n",
    "- Shared validation nodes across multiple pipelines\n",
    "- Environment-specific configurations (dev/staging/prod)\n",
    "- Organization-wide component libraries\n",
    "- Common preprocessing steps\n",
    "- Reusable output formatters\n",
    "\n",
    "**Anti-Patterns to Avoid:**\n",
    "- Over-fragmentation (too many small includes)\n",
    "- Deep nesting (>3 levels)\n",
    "- Circular dependencies\n",
    "- Including everything (reduces readability)\n",
    "\n",
    "### ğŸ”’ Security Features\n",
    "\n",
    "**Built-in Protections:**\n",
    "1. **Circular Include Detection** - Prevents infinite loops\n",
    "2. **Directory Traversal Protection** - Can't escape project root\n",
    "3. **Absolute Path Rejection** - Only relative paths allowed\n",
    "4. **Max Depth Limit** - Prevents excessive nesting (default: 10)\n",
    "\n",
    "### ğŸ“ Recommended Structure\n",
    "\n",
    "```\n",
    "project/\n",
    "â”œâ”€â”€ components/           # Reusable component library\n",
    "â”‚   â”œâ”€â”€ validation/\n",
    "â”‚   â”œâ”€â”€ processing/\n",
    "â”‚   â””â”€â”€ output/\n",
    "â”œâ”€â”€ shared/              # Shared configurations\n",
    "â”‚   â”œâ”€â”€ common-nodes.yaml\n",
    "â”‚   â””â”€â”€ base-config.yaml\n",
    "â”œâ”€â”€ environments/        # Environment configs\n",
    "â”‚   â”œâ”€â”€ dev.yaml\n",
    "â”‚   â”œâ”€â”€ staging.yaml\n",
    "â”‚   â””â”€â”€ prod.yaml\n",
    "â””â”€â”€ pipelines/          # Main pipeline definitions\n",
    "    â”œâ”€â”€ pipeline-a.yaml\n",
    "    â””â”€â”€ pipeline-b.yaml\n",
    "```\n",
    "\n",
    "### ğŸ¯ Key Takeaways\n",
    "\n",
    "1. **DRY Principle** - Include shared components to avoid duplication\n",
    "2. **Composition** - Build complex pipelines from simple, reusable parts\n",
    "3. **Environment Separation** - Use includes for dev/staging/prod configs\n",
    "4. **Security** - Built-in protections prevent common vulnerabilities\n",
    "5. **Maintainability** - Update once, affect all pipelines that include it\n",
    "\n",
    "### ğŸ”— Related Topics\n",
    "\n",
    "- Environment variables in YAML (`${VAR}` syntax)\n",
    "- Jinja2 templates in YAML (`{{ variable }}` syntax)  \n",
    "- Multi-document YAML for environment configs\n",
    "- YAML validation and schema checking\n",
    "\n",
    "The `!include` directive enables enterprise-scale pipeline composition patterns while maintaining security and simplicity!"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}
